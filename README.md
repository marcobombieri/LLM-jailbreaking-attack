# LLM-jailbreaking-attack-and-effects

Repository for the paper "The Dangerous Effects of a Frustratingly Easy LLMs Jailbreak Attack". 
This repository is still under construction.

- list_of_prompts.csv contains the list of prompts used in this paper
- In "datasets_after_jailbreaking" are the datasets of jailbroken answers provided by the three LLMs annotated with "A" (factually incorrect or toxic), "B" (factually correct and not toxic, but unsound to read) or "C" (correct).
